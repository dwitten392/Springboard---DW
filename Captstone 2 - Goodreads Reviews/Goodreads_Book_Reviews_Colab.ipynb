{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Goodreads Book Reviews Colab.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPQleh2aSKALyzIBFLw/54X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dwitten392/Springboard---DW/blob/master/Captstone%202%20-%20Goodreads%20Reviews/Goodreads_Book_Reviews_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdFaZKgyhUhr",
        "colab_type": "text"
      },
      "source": [
        "# Sentiment Analysis - Goodreads Reviews\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXobpZ3Khpi5",
        "colab_type": "text"
      },
      "source": [
        "Loading the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEbqMKBLg4vI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "232aa9fc-4125-4804-b08c-ae4426240e0c"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
        "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from tensorflow.keras.models import Model, save_model, load_model\n",
        "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers\n",
        "\n",
        "import re\n",
        "import os\n",
        "from IPython.display import HTML\n",
        "import seaborn as sns\n",
        "sns.set(style=\"darkgrid\")\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxClF32qUWGC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "cbdb5b82-5c25-439f-e13d-0855c0928340"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaVjmx20mufd",
        "colab_type": "text"
      },
      "source": [
        "Loading review text and sentiment data files and GloVe model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWgNbr7sLjYd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "6c03c602-2999-4b25-d7ea-a17b4bb4981d"
      },
      "source": [
        "ls -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 8\n",
            "drwx------ 4 root root 4096 May 31 13:00 \u001b[0m\u001b[01;34mdrive\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4096 May 27 16:27 \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqz01oscl6Xm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "a0c2e85e-be9b-4db4-b825-637af8da180d"
      },
      "source": [
        "! unzip 'drive/My Drive/glove.6B.zip'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  drive/My Drive/glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFxKqt8mZbDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#using the 300 dimensional vectors\n",
        "EMBEDDING_FILE='glove.6B.300d.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Sm5X3YTxaAa",
        "colab_type": "text"
      },
      "source": [
        "Loading data into a dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAuJNZc6v4vu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle as pkl\n",
        "#unpickle the results\n",
        "with open(\"drive/My Drive/sentiment.txt\", \"rb\") as fp:   # Unpickling\n",
        "    sentiment = pkl.load(fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXKfHnQxdrzu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#unpickle the results\n",
        "with open(\"drive/My Drive/review_text1.txt\", \"rb\") as fp:   # Unpickling\n",
        "    review_text1 = pkl.load(fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PH8Y16ztkyoa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#unpickle the results\n",
        "with open(\"drive/My Drive/review_text2.txt\", \"rb\") as fp:   # Unpickling\n",
        "    review_text2 = pkl.load(fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7pySYbYxUCA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "review_text = review_text1.append(review_text2).astype(\"string\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mmw9r9oZlczX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "714b95f1-5591-4082-a2a0-1683fca4bd78"
      },
      "source": [
        "len(review_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "806952"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_AfqaH8aFlb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "4bbee022-4db8-4d4d-d319-ad550b0dd86b"
      },
      "source": [
        "type(review_text)\n",
        "print(\"\")\n",
        "review_text[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A fun, fast paced science fiction thriller. I read it in 2 nights and couldn\\'t put it down. The book is about the quantum theory of many worlds which states that all decisions we make throughout our lives basically create branches, and that each possible path through the decision tree can be thought of as a parallel world. And in this book, someone invents a way to switch between these worlds. This was nicely alluded to/foreshadowed in this quote: \\n \"I think about all the choices we\\'ve made that created this moment. Us sitting here together at this beautiful table. Then I think of all the possible events that could have stopped this moment from ever happening, and it all feels, I don\\'t know...\" \"What?\" \"So fragile.\" Now he becomes thoughtful for a moment. He says finally, \"It\\'s terrifying when you consider that every thought we have, every choice we could possibly make, branches into a new world.\" \\n (view spoiler)[This book can\\'t be discussed without spoilers. It is a book about choice and regret. Ever regret not chasing the girl of your dreams so you can focus on your career? Well Jason2 made that choice and then did regret it. Clearly the author is trying to tell us to optimize for happiness - to be that second rate physics teacher at a community college if it means you can have a happy life. I\\'m being snarky because while there is certainly something to that, you also have to have meaning in your life that comes from within. I thought the book was a little shallow on this dimension. In fact, all the characters were fairly shallow. Daniela was the perfect wife. Ryan the perfect antithesis of Jason. Amanda the perfect loyal traveling companion, etc. This, plus the fact that the book was weak on the science are what led me to take a few stars off - but I\\'d still read it again if I could go back in time - was a very fun and engaging read. \\n If you want to really minimize regret, you have to live your life to avoid it in the first place. Regret can\\'t be hacked, which is kind of the point of the book. My favorite book about regret is Remains of the Day. I do really like the visualization of the decision tree though - that is a powerful concept. \\n \"Every moment, every breath, contains a choice. But life is imperfect. We make the wrong choices. So we end up living in a state of perpetual regret, and is there anything worse? I built something that could actually eradicate regret. Let you find worlds where you made the right choice.\" Daniela says, \"Life doesn\\'t work that way. You live with your choices and learn. You don\\'t cheat the system.\" \\n (hide spoiler)]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8OKDUg6m26-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "review_df = pd.DataFrame({'sentiment':sentiment, 'review_text':review_text.values})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2QW435syb7m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "9d4483b1-6118-448b-efbe-5eeafeb42417"
      },
      "source": [
        "review_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>A fun, fast paced science fiction thriller. I ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neutral</td>\n",
              "      <td>This book has a great premise, and is full of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>A fun, dark, slightly comical western about tw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neutral</td>\n",
              "      <td>** spoiler alert ** \n",
              " Critics aside, Dan Brown...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neutral</td>\n",
              "      <td>A great finish to the D'Artagnan series - defi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  sentiment                                        review_text\n",
              "0   neutral  A fun, fast paced science fiction thriller. I ...\n",
              "1   neutral  This book has a great premise, and is full of ...\n",
              "2   neutral  A fun, dark, slightly comical western about tw...\n",
              "3   neutral  ** spoiler alert ** \n",
              " Critics aside, Dan Brown...\n",
              "4   neutral  A great finish to the D'Artagnan series - defi..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhGOZsXnyzh5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "fd343f2e-374c-4e6c-ee6c-55e81c4e4b43"
      },
      "source": [
        "review_df['review_text'][10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"3.5 Stars \\n 'The Protector' is a perfectly enjoyable, sexy, fast-paced story. \\n While it perhaps did not live up to JEM's superb story-telling potential, it was nonetheless am interesting and super-sexy story. I loved how the author presented another side to the heroine Camille: to the world, she is a rich, spoiled socialite. But she is actually smart and very ambitious and determined to build her own business from the ground up. She made lots of mistakes in the past, and some of those mistakes might be coming back to haunt her now. \\n Jake is PURE Alpha, a former SAS sniper who suffers from PTSD. Camille does not want his protection, AT ALL, but her father hires Jake to make sure that Camille is safe. Jake is also haunted by his own personal demons, but sees his job with Camille as a chance at redemption. \\n JEM remains one of my auto-buy authors. Her 'This Man' series is without question among my top favorite books of all time! And I absolutely fell in love with Miller in the 'One Night' series, another series that I HIGHLY recommend. Both Jesse and Miller are uber-Alphas beyond compare. \\n So I thought 'The Protector' had lots of sizzling sex scenes and very fast-paced action along with a mystery story as well. While this is not my favorite JEM story, definitely give the one a try if you love this kind of contemporary romance! \\n (ARC provided by the publisher in return for an honest review.)\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfNExkmgoHUv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "bf69a05f-ac55-478c-f3d6-861e26956d4b"
      },
      "source": [
        "review_df['sentiment'].value_counts(dropna=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "positive    403476\n",
              "neutral     261806\n",
              "negative    141670\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Tek3rIv3kba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentiment_df = pd.get_dummies(review_df['sentiment'])\n",
        "review_df = pd.concat([review_df, sentiment_df], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMu6DKkB3qkS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "91d3219c-a83d-4655-a0fb-155f2415860d"
      },
      "source": [
        "review_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review_text</th>\n",
              "      <th>negative</th>\n",
              "      <th>neutral</th>\n",
              "      <th>positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>A fun, fast paced science fiction thriller. I ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neutral</td>\n",
              "      <td>This book has a great premise, and is full of ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>A fun, dark, slightly comical western about tw...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neutral</td>\n",
              "      <td>** spoiler alert ** \n",
              " Critics aside, Dan Brown...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neutral</td>\n",
              "      <td>A great finish to the D'Artagnan series - defi...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  sentiment  ... positive\n",
              "0   neutral  ...        0\n",
              "1   neutral  ...        0\n",
              "2   neutral  ...        0\n",
              "3   neutral  ...        0\n",
              "4   neutral  ...        0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQBjC-3DzaJi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(review_df.drop(['sentiment'], axis=1), review_df['sentiment'],\n",
        "                                                test_size=0.2, random_state=111, stratify = review_df['sentiment'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNzmlHa734hJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_classes = [\"negative\", \"neutral\", 'positive']\n",
        "y = X_train[list_classes].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv64kHHjXGBY",
        "colab_type": "text"
      },
      "source": [
        "## Model 1 (20,000 Max Features, 300 max length)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54QKDpsQovuv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_size = 300 # how big is each word vector (300 for large corpus)\n",
        "max_features = 20000 # how many unique words to use (i.e num rows in embedding vector)\n",
        "max_len = 300 # max number of words in a comment to use (75% percentile for corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLA8XQL4pBfj",
        "colab_type": "text"
      },
      "source": [
        "Standard keras preprocessing, to turn each comment into a list of word indexes of equal length (with truncation or padding as needed)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANAV-HJopC8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=max_features) #tokenizing raw text\n",
        "tokenizer.fit_on_texts(list(X_train.review_text.values))\n",
        "list_tokenized_train = tokenizer.texts_to_sequences(X_train.review_text.values)\n",
        "list_tokenized_test = tokenizer.texts_to_sequences(X_test.review_text.values)\n",
        "X_t = pad_sequences(list_tokenized_train, maxlen=max_len)\n",
        "X_te = pad_sequences(list_tokenized_test, maxlen=max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oy51xyrSpzVu",
        "colab_type": "text"
      },
      "source": [
        "Read the glove word vectors (space delimited strings) into a dictionary from word->vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ad2zTEw0pydl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
        "embeddings_index = dict(get_coefs(*o.strip().split()) for o in open(EMBEDDING_FILE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7Nscj-Zsngc",
        "colab_type": "text"
      },
      "source": [
        "Use these vectors to create our embedding matrix, with random initialization for words that aren't in GloVe. We'll use the same mean and stdev of embeddings the GloVe has when generating the random init."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hss7RQdsoD6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "461f2474-1082-438f-a095-3070e987580f"
      },
      "source": [
        "all_embs = np.stack(embeddings_index.values())\n",
        "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
        "emb_mean,emb_std"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.0039050116, 0.38177028)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTMJfc2Zsxe2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "nb_words = min(max_features, len(word_index))\n",
        "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features: continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDwHvAgow3_2",
        "colab_type": "text"
      },
      "source": [
        "Simple bidirectional LSTM with two fully connected layers. We add some dropout to the LSTM since even 2 epochs is enough to overfit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48BaZFWOwKJ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "621df65c-8de2-4a7f-9853-2c35b882ef46"
      },
      "source": [
        "inp = Input(shape=(max_len,))\n",
        "x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
        "x = Bidirectional(LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(x)\n",
        "x = GlobalMaxPool1D()(x)\n",
        "x = Dense(50, activation=\"relu\")(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(3, activation=\"sigmoid\")(x)\n",
        "model = Model(inputs=inp, outputs=x)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWgwkNnt1GBb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "1deed5be-5f0c-49de-d11e-6db1ef5a7e58"
      },
      "source": [
        "model.fit(X_t, y, batch_size=100, epochs=3, validation_split=0.2);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "5165/5165 [==============================] - 16899s 3s/step - loss: 0.3811 - accuracy: 0.7240 - val_loss: 0.3505 - val_accuracy: 0.7512\n",
            "Epoch 2/3\n",
            "5165/5165 [==============================] - 17012s 3s/step - loss: 0.3311 - accuracy: 0.7702 - val_loss: 0.3412 - val_accuracy: 0.7614\n",
            "Epoch 3/3\n",
            "5165/5165 [==============================] - 16163s 3s/step - loss: 0.3073 - accuracy: 0.7914 - val_loss: 0.3456 - val_accuracy: 0.7618\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLQcGw8u2pOG",
        "colab_type": "text"
      },
      "source": [
        "Predictions for the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbUz_eX92m3I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1a15509c-6dce-4184-e22e-2485c70c53c6"
      },
      "source": [
        "y_test_preds = model.predict([X_te], batch_size=1024, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "158/158 [==============================] - 40s 252ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4GRE3di2vyG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "445de3e8-87d0-49da-8478-db0276d7aac7"
      },
      "source": [
        "y_test_preds.shape\n",
        "y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(161391, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(161391,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bpybt4D29dh",
        "colab_type": "text"
      },
      "source": [
        "Save the model to our drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVmwSHCA27K-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('drive/My Drive/bidirectional_LSTM_sentiment_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTB0pe_JrDz8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0cea9c9f-773b-45be-c27f-774935a51f03"
      },
      "source": [
        "model_structure = model.to_json()\n",
        "with open(\"drive/My Drive/bidirectional_LSTM_sentiment_model.json\", \"w\") as json_file:\n",
        "  json_file.write(model_structure)\n",
        "  model.save_weights(\"LSTM_weights.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3342"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDB3luSFXW7h",
        "colab_type": "text"
      },
      "source": [
        "## Model 2 (25,000 Max Features and 400 Max Length)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_AV3xdf3XVaV",
        "colab": {}
      },
      "source": [
        "embed_size = 300 # how big is each word vector (300 for large corpus)\n",
        "max_features = 25000 # how many unique words to use (i.e num rows in embedding vector)\n",
        "max_len = 400 # max number of words in a comment to use"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KtpPGRM5XVa7"
      },
      "source": [
        "Standard keras preprocessing, to turn each comment into a list of word indexes of equal length (with truncation or padding as needed)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ePsFSLqCXVbP",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=max_features) #tokenizing raw text\n",
        "tokenizer.fit_on_texts(list(X_train.review_text.values))\n",
        "list_tokenized_train = tokenizer.texts_to_sequences(X_train.review_text.values)\n",
        "list_tokenized_test = tokenizer.texts_to_sequences(X_test.review_text.values)\n",
        "X_t = pad_sequences(list_tokenized_train, maxlen=max_len)\n",
        "X_te = pad_sequences(list_tokenized_test, maxlen=max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sv1Ey5oMXVbn"
      },
      "source": [
        "Read the glove word vectors (space delimited strings) into a dictionary from word->vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3UZh7YxbXVbs",
        "colab": {}
      },
      "source": [
        "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
        "embeddings_index = dict(get_coefs(*o.strip().split()) for o in open(EMBEDDING_FILE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0wPBNSHsXVcH"
      },
      "source": [
        "Use these vectors to create our embedding matrix, with random initialization for words that aren't in GloVe. We'll use the same mean and stdev of embeddings the GloVe has when generating the random init."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GM6tvaRpXVcQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "14269645-7ff8-40f8-a021-60cdfaee148a"
      },
      "source": [
        "all_embs = np.stack(embeddings_index.values())\n",
        "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
        "emb_mean,emb_std"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.0039050116, 0.38177028)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "buw627pxXVco",
        "colab": {}
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "nb_words = min(max_features, len(word_index))\n",
        "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features: continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6EnGrJ95XVdA"
      },
      "source": [
        "Simple bidirectional LSTM with two fully connected layers. We add some dropout to the LSTM since even 2 epochs is enough to overfit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TS2a2pwsXVdG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "outputId": "2fa764df-451e-4df0-a406-1ee26c8ea91a"
      },
      "source": [
        "inp = Input(shape=(max_len,))\n",
        "x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
        "x = Bidirectional(LSTM(50, return_sequences=True, dropout=0.10, recurrent_dropout=0.10))(x)\n",
        "x = GlobalMaxPool1D()(x)\n",
        "x = Dense(50, activation=\"relu\")(x)\n",
        "x = Dropout(0.15)(x)\n",
        "x = Dense(3, activation=\"sigmoid\")(x)\n",
        "model2 = Model(inputs=inp, outputs=x)\n",
        "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axKBm7R-YZuA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_te = X_test[list_classes].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "elhdXeo9XVdh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "5d04ec6b-0feb-413c-f224-45373f2eff03"
      },
      "source": [
        "model2.fit(X_t, y, batch_size=96, epochs=2, validation_data=(X_te, y_te));"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "6725/6725 [==============================] - 19090s 3s/step - loss: 0.3696 - accuracy: 0.7352 - val_loss: 0.3363 - val_accuracy: 0.7643\n",
            "Epoch 2/2\n",
            "6725/6725 [==============================] - 18931s 3s/step - loss: 0.3226 - accuracy: 0.7785 - val_loss: 0.3287 - val_accuracy: 0.7705\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sbbvoKFCXVd9"
      },
      "source": [
        "Predictions for the test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "B9BGFuphXVey"
      },
      "source": [
        "Save the model to our drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M_CF4js5XVe1",
        "colab": {}
      },
      "source": [
        "model2.save('drive/My Drive/bidirectional_LSTM_sentiment_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QlndB4a4XVe_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "a002f982-7b9a-4828-8045-b7314786dc36"
      },
      "source": [
        "from tensorflow import keras\n",
        "model = keras.models.load_model('drive/My Drive/bidirectional_LSTM_sentiment_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shQKFpj-0Jpa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bea7be55-8b73-497c-ff0a-edd04a6d6686"
      },
      "source": [
        "y_test_preds = model.predict([X_te], batch_size=1024, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "158/158 [==============================] - 42s 268ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOZ3jlyH56TC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4df8cda0-d334-4a62-e82d-9a61e044587a"
      },
      "source": [
        "y_test_preds.shape\n",
        "y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(161391, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(161391,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9elqyXJNGlAH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bf700594-edba-4ded-efe4-22a50c81dff6"
      },
      "source": [
        "y_test_preds.argmax"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function ndarray.argmax>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PAa4eQ1HTf2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "08c32cb6-248c-4aa2-9d0d-f4b827b77f45"
      },
      "source": [
        "y_te[0:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1PsgmoN6E2f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "7979bbba-ad36-48ab-a133-be5cddd7c8e3"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, log_loss\n",
        "\n",
        "\n",
        "lstm_accuracy_score = accuracy_score(y_te.argmax(axis =1), y_test_preds.argmax(axis=1))\n",
        "lstm_f1_value = f1_score(y_te.argmax(axis=1), y_test_preds.argmax(axis=1), average ='weighted')\n",
        "lstm_log_loss_value = log_loss(y_te, y_test_preds, normalize=True)\n",
        "print(\"Accuracy Score:     {:0.4f}\".format(lstm_accuracy_score))\n",
        "print(\"       F-score:     {:0.4f}\".format(lstm_f1_value))\n",
        "print(\"      Log Loss:     {:0.4f}\".format(lstm_log_loss_value))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score:     0.7705\n",
            "       F-score:     0.7696\n",
            "      Log Loss:     0.5272\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tliSf3i-Id6n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "6a460985-761d-4dd6-ecd9-8711de3e4dd5"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "plt.figure(figsize=(8,6))\n",
        "fpr, tpr, _ = roc_curve(y_te, y_test_preds)\n",
        "auc = roc_auc_score(y_te, y_test_preds)\n",
        "plt.plot(fpr,tpr,  color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % auc)\n",
        "plt.legend(loc=4)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC CURVE')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-e1cefc59c246>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'darkorange'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ROC curve (area = %0.2f)'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \"\"\"\n\u001b[1;32m    770\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 771\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    534\u001b[0m     if not (y_type == \"binary\" or\n\u001b[1;32m    535\u001b[0m             (y_type == \"multiclass\" and pos_label is not None)):\n\u001b[0;32m--> 536\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: multilabel-indicator format is not supported"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4H4ejaUGJd-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}